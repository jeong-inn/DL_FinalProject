{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcf4e64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>sub_group</th>\n",
       "      <th>subject</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SLI</td>\n",
       "      <td>A</td>\n",
       "      <td>725</td>\n",
       "      <td>ENNI/SLI/A/725.cha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SLI</td>\n",
       "      <td>A</td>\n",
       "      <td>568</td>\n",
       "      <td>ENNI/SLI/A/568.cha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SLI</td>\n",
       "      <td>A</td>\n",
       "      <td>678</td>\n",
       "      <td>ENNI/SLI/A/678.cha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SLI</td>\n",
       "      <td>A</td>\n",
       "      <td>825</td>\n",
       "      <td>ENNI/SLI/A/825.cha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SLI</td>\n",
       "      <td>A</td>\n",
       "      <td>878</td>\n",
       "      <td>ENNI/SLI/A/878.cha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  group sub_group  subject            filename\n",
       "0   SLI         A      725  ENNI/SLI/A/725.cha\n",
       "1   SLI         A      568  ENNI/SLI/A/568.cha\n",
       "2   SLI         A      678  ENNI/SLI/A/678.cha\n",
       "3   SLI         A      825  ENNI/SLI/A/825.cha\n",
       "4   SLI         A      878  ENNI/SLI/A/878.cha"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"split/ENNI_train.csv\")\n",
    "dev_df   = pd.read_csv(\"split/ENNI_dev.csv\")\n",
    "test_df  = pd.read_csv(\"split/ENNI_test.csv\")\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e76e5cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 281/281 [00:00<00:00, 1272.78it/s]\n",
      "100%|█████████████████████████████████████████| 35/35 [00:00<00:00, 1228.07it/s]\n",
      "100%|█████████████████████████████████████████| 36/36 [00:00<00:00, 1231.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장 완료: train_ready.csv, dev_ready.csv, test_ready.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------------\n",
    "# 1) CHI 발화 추출 함수\n",
    "# ------------------------------\n",
    "def extract_chi_text(path):\n",
    "    texts = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"*CHI:\"):\n",
    "                sent = re.sub(r\"\\x15.+?\\x15\", \"\", line)\n",
    "                sent = sent.replace(\"*CHI:\", \"\").strip()\n",
    "                texts.append(sent)\n",
    "    return \" \".join(texts)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 2) Split된 CSV 불러오기\n",
    "# ------------------------------\n",
    "train_df = pd.read_csv(\"split/ENNI_train.csv\")\n",
    "dev_df   = pd.read_csv(\"split/ENNI_dev.csv\")\n",
    "test_df  = pd.read_csv(\"split/ENNI_test.csv\")\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 3) 텍스트 & 라벨 추가 함수\n",
    "# ------------------------------\n",
    "def add_text_and_label(df):\n",
    "    texts, labels = [], []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        path = row[\"filename\"]\n",
    "        text = extract_chi_text(path)\n",
    "        texts.append(text)\n",
    "\n",
    "        label = 1 if row[\"group\"] == \"SLI\" else 0\n",
    "        labels.append(label)\n",
    "\n",
    "    df[\"text\"] = texts\n",
    "    df[\"label\"] = labels\n",
    "    return df\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 4) 적용 후 저장\n",
    "# ------------------------------\n",
    "train_df = add_text_and_label(train_df)\n",
    "dev_df   = add_text_and_label(dev_df)\n",
    "test_df  = add_text_and_label(test_df)\n",
    "\n",
    "train_df.to_csv(\"train_ready.csv\", index=False)\n",
    "dev_df.to_csv(\"dev_ready.csv\", index=False)\n",
    "test_df.to_csv(\"test_ready.csv\", index=False)\n",
    "\n",
    "print(\"저장 완료: train_ready.csv, dev_ready.csv, test_ready.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f798ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class weights: {0: 0.6162280701754386, 1: 2.650943396226415}\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best params: {'clf__C': 10, 'tfidf__max_df': 1.0, 'tfidf__max_features': 2000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1)}\n",
      "Dev Accuracy: 0.8\n",
      "Dev F1: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        28\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.80        35\n",
      "   macro avg       0.40      0.50      0.44        35\n",
      "weighted avg       0.64      0.80      0.71        35\n",
      "\n",
      "Confusion matrix:\n",
      " [[28  0]\n",
      " [ 7  0]]\n",
      "Test Accuracy: 0.8611111111111112\n",
      "Test F1: 0.2857142857142857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        30\n",
      "           1       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.86        36\n",
      "   macro avg       0.93      0.58      0.60        36\n",
      "weighted avg       0.88      0.86      0.82        36\n",
      "\n",
      "Confusion matrix:\n",
      " [[30  0]\n",
      " [ 5  1]]\n",
      "모델 저장 완료: tfidf_logreg_enni_bestjoblib.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.4s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.9s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.1s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.2s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   3.1s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   2.1s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   1.0s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.2s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.1s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   4.1s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   3.2s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.1s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.2s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   2.1s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   1.0s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.3s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.5s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   3.1s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   3.0s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.0s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.0s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.0s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.1s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   3.0s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.3s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.2s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   1.0s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.3s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.2s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   3.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.3s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.4s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.2s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.8s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   2.1s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.5s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   3.5s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.3s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.1s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   3.2s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.1s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.4s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.3s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   2.3s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   3.3s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   2.3s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.1s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.1s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.9s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.2s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.2s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.5s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.3s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   3.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   3.0s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.9s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.1s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.9s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.2s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.2s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   3.0s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.2s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   2.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.4s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   2.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.2s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.9s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.9s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.9s\n",
      "[CV] END clf__C=0.01, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.2s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.1s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.2s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.4s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=0.1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.1s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=1, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   3.0s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=1, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=5000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   3.1s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.8, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.3s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.3s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   1.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.5s\n",
      "[CV] END clf__C=10, tfidf__max_df=0.9, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   2.1s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.5s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=2000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   1.6s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=1, tfidf__ngram_range=(1, 2); total time=   2.1s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=5000, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   2.0s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.9s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=2, tfidf__ngram_range=(1, 2); total time=   3.0s\n",
      "[CV] END clf__C=10, tfidf__max_df=1.0, tfidf__max_features=None, tfidf__min_df=3, tfidf__ngram_range=(1, 2); total time=   2.3s\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# 1) 데이터 로드 (train/dev/test)\n",
    "# -----------------------------\n",
    "train_df = pd.read_csv(\"train_ready.csv\")   # 이전 단계에서 만든 파일\n",
    "dev_df   = pd.read_csv(\"dev_ready.csv\")\n",
    "test_df  = pd.read_csv(\"test_ready.csv\")\n",
    "\n",
    "train_texts, train_labels = train_df[\"text\"].tolist(), train_df[\"label\"].tolist()\n",
    "dev_texts, dev_labels     = dev_df[\"text\"].tolist(), dev_df[\"label\"].tolist()\n",
    "test_texts, test_labels   = test_df[\"text\"].tolist(), test_df[\"label\"].tolist()\n",
    "\n",
    "# -----------------------------\n",
    "# 2) 클래스 가중치 계산 (불균형 처리)\n",
    "# -----------------------------\n",
    "import numpy as np\n",
    "classes = np.unique(train_labels)\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=train_labels)\n",
    "class_weight_dict = {c: w for c, w in zip(classes, class_weights)}\n",
    "print(\"class weights:\", class_weight_dict)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) 파이프라인 + 하이퍼파라미터 그리드 (LogisticRegression baseline)\n",
    "# -----------------------------\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"clf\", LogisticRegression(max_iter=5000, solver=\"saga\"))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"tfidf__max_df\": [0.8, 0.9, 1.0],\n",
    "    \"tfidf__min_df\": [1, 2, 3],\n",
    "    \"tfidf__ngram_range\": [(1,1), (1,2)],\n",
    "    \"tfidf__max_features\": [2000, 5000, None],\n",
    "    \"clf__C\": [0.01, 0.1, 1, 10],\n",
    "    # class weight은 모델 인스턴스 생성시 적용하므로 그리드에 넣지 않음\n",
    "}\n",
    "\n",
    "# GridSearchCV: dev(검증) 대신 train+dev 합쳐서 CV 쓰지 말고 dev로 튜닝하려면 scoring 후 수동 비교 가능.\n",
    "# 여기서는 간단히 train만으로 CV (5-fold) 수행 — 데이터가 그리 큰 편은 아님.\n",
    "gs = GridSearchCV(pipeline, param_grid, scoring=\"f1\", cv=5, n_jobs=-1, verbose=2)\n",
    "gs.fit(train_texts, train_labels)\n",
    "\n",
    "print(\"Best params:\", gs.best_params_)\n",
    "best_model = gs.best_estimator_\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Dev에서 성능 확인 (튜닝 결과 확인)\n",
    "# -----------------------------\n",
    "dev_preds = best_model.predict(dev_texts)\n",
    "print(\"Dev Accuracy:\", accuracy_score(dev_labels, dev_preds))\n",
    "print(\"Dev F1:\", f1_score(dev_labels, dev_preds))\n",
    "print(classification_report(dev_labels, dev_preds))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(dev_labels, dev_preds))\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Test 최종 평가\n",
    "# -----------------------------\n",
    "test_preds = best_model.predict(test_texts)\n",
    "print(\"Test Accuracy:\", accuracy_score(test_labels, test_preds))\n",
    "print(\"Test F1:\", f1_score(test_labels, test_preds))\n",
    "print(classification_report(test_labels, test_preds))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(test_labels, test_preds))\n",
    "\n",
    "# -----------------------------\n",
    "# 6) 모델 저장\n",
    "# -----------------------------\n",
    "joblib.dump(best_model, \"tfidf_logreg_enni_bestjoblib.pkl\")\n",
    "print(\"모델 저장 완료: tfidf_logreg_enni_bestjoblib.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964d9e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "문제는 코드가 아니라 데이터, 클래스 불균형, 모델 선택에 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8df6a4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 GloVe 임베딩 로딩 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:06, 61563.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로드 완료! | 단어 수: 400000\n",
      "🔹 LSTM 인코딩 중...\n",
      "\n",
      "📌 분류 성능:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       1.0\n",
      "           1       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# -------------------------\n",
    "# 1. 텍스트 전처리\n",
    "# -------------------------\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9 ]\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "# -------------------------\n",
    "# 2. 토크나이징\n",
    "# -------------------------\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "# -------------------------\n",
    "# 3. GloVe 로딩\n",
    "# -------------------------\n",
    "def load_glove(path, dim=100):\n",
    "    print(\"🔹 GloVe 임베딩 로딩 중...\")\n",
    "    embeddings = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in tqdm(f):\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    print(f\"로드 완료! | 단어 수: {len(embeddings)}\")\n",
    "    return embeddings\n",
    "\n",
    "# -------------------------\n",
    "# 4. 문장 → 임베딩 시퀀스 변환\n",
    "# -------------------------\n",
    "def sentence_to_vectors(tokens, glove, dim=100, max_len=30):\n",
    "    vectors = []\n",
    "    for tok in tokens[:max_len]:\n",
    "        if tok in glove:\n",
    "            vectors.append(glove[tok])\n",
    "        else:\n",
    "            vectors.append(np.zeros(dim))\n",
    "    # padding\n",
    "    while len(vectors) < max_len:\n",
    "        vectors.append(np.zeros(dim))\n",
    "    return np.array(vectors)\n",
    "\n",
    "# -------------------------\n",
    "# 5. NumPy LSTM 구현\n",
    "# -------------------------\n",
    "class NumpyLSTM:\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Xavier 초기화\n",
    "        scale = 1.0 / np.sqrt(hidden_dim)\n",
    "\n",
    "        self.W_f = np.random.randn(hidden_dim, input_dim) * scale\n",
    "        self.U_f = np.random.randn(hidden_dim, hidden_dim) * scale\n",
    "        self.b_f = np.zeros((hidden_dim, 1))\n",
    "\n",
    "        self.W_i = np.random.randn(hidden_dim, input_dim) * scale\n",
    "        self.U_i = np.random.randn(hidden_dim, hidden_dim) * scale\n",
    "        self.b_i = np.zeros((hidden_dim, 1))\n",
    "\n",
    "        self.W_c = np.random.randn(hidden_dim, input_dim) * scale\n",
    "        self.U_c = np.random.randn(hidden_dim, hidden_dim) * scale\n",
    "        self.b_c = np.zeros((hidden_dim, 1))\n",
    "\n",
    "        self.W_o = np.random.randn(hidden_dim, input_dim) * scale\n",
    "        self.U_o = np.random.randn(hidden_dim, hidden_dim) * scale\n",
    "        self.b_o = np.zeros((hidden_dim, 1))\n",
    "\n",
    "    def step(self, x_t, h_prev, c_prev):\n",
    "        x_t = x_t.reshape(-1, 1)\n",
    "\n",
    "        f_t = sigmoid(self.W_f @ x_t + self.U_f @ h_prev + self.b_f)\n",
    "        i_t = sigmoid(self.W_i @ x_t + self.U_i @ h_prev + self.b_i)\n",
    "        o_t = sigmoid(self.W_o @ x_t + self.U_o @ h_prev + self.b_o)\n",
    "        c_hat = np.tanh(self.W_c @ x_t + self.U_c @ h_prev + self.b_c)\n",
    "\n",
    "        c_t = f_t * c_prev + i_t * c_hat\n",
    "        h_t = o_t * np.tanh(c_t)\n",
    "\n",
    "        return h_t, c_t\n",
    "    \n",
    "    def forward(self, sequence):\n",
    "        h = np.zeros((self.hidden_dim, 1))\n",
    "        c = np.zeros((self.hidden_dim, 1))\n",
    "\n",
    "        for x_t in sequence:\n",
    "            h, c = self.step(x_t, h, c)\n",
    "        return h.flatten()   # 마지막 hidden state 반환\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# -------------------------\n",
    "# 6. 전체 파이프라인 실행\n",
    "# -------------------------\n",
    "# 예시 데이터 (교수님이 말한 단순 데이터)\n",
    "texts = [\n",
    "    \"This movie is great\",\n",
    "    \"I hated this film\",\n",
    "    \"What a wonderful story\",\n",
    "    \"Terrible acting and bad plot\",\n",
    "]\n",
    "labels = [1, 0, 1, 0]\n",
    "\n",
    "texts = [clean_text(t) for t in texts]\n",
    "tokenized = [tokenize(t) for t in texts]\n",
    "\n",
    "# GloVe 로딩\n",
    "glove = load_glove(\"glove.6B.100d.txt\", dim=100)\n",
    "\n",
    "# 문장 → 벡터 변환\n",
    "X = np.array([\n",
    "    sentence_to_vectors(tokens, glove, dim=100, max_len=30)\n",
    "    for tokens in tokenized\n",
    "])\n",
    "\n",
    "# LSTM 인코딩\n",
    "print(\"🔹 LSTM 인코딩 중...\")\n",
    "lstm = NumpyLSTM(input_dim=100, hidden_dim=64)\n",
    "\n",
    "X_encoded = np.array([lstm.forward(sentence) for sentence in X])\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, labels, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 7. Scikit-learn 분류기 학습\n",
    "# -------------------------\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "print(\"\\n📌 분류 성능:\\n\")\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f298f1ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3943797197.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/w5/1h0crrlj5hx238pnm9g4gcgw0000gn/T/ipykernel_72955/3943797197.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    지금 나온 0% 성능은 정상이야.\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "모델이 잘못된 게 아니라 데이터가 너무 적어서 생기는 현상\n",
    "1) 데이터 4개 → train 3개, test 1개\n",
    "\n",
    "test가 1개면 정밀도/재현률 계산이 불가능\n",
    "\n",
    "스케일에 민감한 Logistic Regression이 3개 데이터로는 학습이 불가\n",
    "\n",
    "2) LSTM 파라미터는 랜덤 초기화\n",
    "\n",
    "LSTM은 backpropagation으로 학습해야 의미 있는 representation을 만든다.\n",
    "하지만 지금은 “학습 없는 LSTM 인코더” → 사실상 랜덤 feature extractor.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01575bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading GloVe: 400000it [00:06, 60248.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Train ===\n",
      "Accuracy: 1.0\n",
      "F1: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       228\n",
      "           1       1.00      1.00      1.00        53\n",
      "\n",
      "    accuracy                           1.00       281\n",
      "   macro avg       1.00      1.00      1.00       281\n",
      "weighted avg       1.00      1.00      1.00       281\n",
      "\n",
      "Confusion matrix:\n",
      " [[228   0]\n",
      " [  0  53]]\n",
      "=== Dev ===\n",
      "Accuracy: 0.8\n",
      "F1: 0.5333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87        28\n",
      "           1       0.50      0.57      0.53         7\n",
      "\n",
      "    accuracy                           0.80        35\n",
      "   macro avg       0.69      0.71      0.70        35\n",
      "weighted avg       0.81      0.80      0.80        35\n",
      "\n",
      "Confusion matrix:\n",
      " [[24  4]\n",
      " [ 3  4]]\n",
      "=== Test ===\n",
      "Accuracy: 0.6666666666666666\n",
      "F1: 0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.73      0.79        30\n",
      "           1       0.20      0.33      0.25         6\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.52      0.53      0.52        36\n",
      "weighted avg       0.74      0.67      0.70        36\n",
      "\n",
      "Confusion matrix:\n",
      " [[22  8]\n",
      " [ 4  2]]\n",
      "저장 완료: svm_glove_lstm_svm.pkl, scaler_glove_lstm.pkl, tfidf_glove.pkl\n"
     ]
    }
   ],
   "source": [
    "# GloVe + NumPy LSTM + SVM 파이프라인 (Jupyter에서 실행)\n",
    "# 전제: glove.6B.100d.txt 가 현재 작업 디렉토리에 있음\n",
    "# 주의: 대량의 데이터면 메모리/속도 고려해야 함\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# --------------------------\n",
    "# 1) 전처리 함수\n",
    "# --------------------------\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "# --------------------------\n",
    "# 2) GloVe 로딩 (이미 다운된 파일 사용)\n",
    "# --------------------------\n",
    "def load_glove(path, dim=100):\n",
    "    glove = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in tqdm(f, desc=\"Loading GloVe\"):\n",
    "            parts = line.rstrip().split(\" \")\n",
    "            word = parts[0]\n",
    "            vec = np.asarray(parts[1:], dtype=np.float32)\n",
    "            if vec.shape[0] == dim:\n",
    "                glove[word] = vec\n",
    "    return glove\n",
    "\n",
    "# 예: glove = load_glove(\"glove.6B.100d.txt\", dim=100)\n",
    "# EMBDIM = 100\n",
    "\n",
    "# --------------------------\n",
    "# 3) 문장 → GloVe 시퀀스 변환\n",
    "# --------------------------\n",
    "def sentence_to_seq(tokens, glove, dim=100, max_len=30):\n",
    "    seq = []\n",
    "    for t in tokens[:max_len]:\n",
    "        if t in glove:\n",
    "            seq.append(glove[t])\n",
    "        else:\n",
    "            seq.append(np.zeros(dim, dtype=np.float32))\n",
    "    # padding\n",
    "    while len(seq) < max_len:\n",
    "        seq.append(np.zeros(dim, dtype=np.float32))\n",
    "    return np.array(seq)  # shape: (max_len, dim)\n",
    "\n",
    "# --------------------------\n",
    "# 4) 간단한 NumPy LSTM (forward only)\n",
    "#    - 학습하지 않고 feature extractor로 사용\n",
    "# --------------------------\n",
    "class NumPyLSTMEncoder:\n",
    "    def __init__(self, input_dim, hidden_dim, seed=42):\n",
    "        np.random.seed(seed)\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # 작은 값으로 초기화\n",
    "        r = 0.1\n",
    "        self.W_f = np.random.randn(hidden_dim, input_dim) * r\n",
    "        self.U_f = np.random.randn(hidden_dim, hidden_dim) * r\n",
    "        self.b_f = np.zeros((hidden_dim,1))\n",
    "\n",
    "        self.W_i = np.random.randn(hidden_dim, input_dim) * r\n",
    "        self.U_i = np.random.randn(hidden_dim, hidden_dim) * r\n",
    "        self.b_i = np.zeros((hidden_dim,1))\n",
    "\n",
    "        self.W_c = np.random.randn(hidden_dim, input_dim) * r\n",
    "        self.U_c = np.random.randn(hidden_dim, hidden_dim) * r\n",
    "        self.b_c = np.zeros((hidden_dim,1))\n",
    "\n",
    "        self.W_o = np.random.randn(hidden_dim, input_dim) * r\n",
    "        self.U_o = np.random.randn(hidden_dim, hidden_dim) * r\n",
    "        self.b_o = np.zeros((hidden_dim,1))\n",
    "\n",
    "    @staticmethod\n",
    "    def _sigmoid(x):\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "    def forward(self, seq):  # seq: (T, input_dim)\n",
    "        h = np.zeros((self.hidden_dim,1))\n",
    "        c = np.zeros((self.hidden_dim,1))\n",
    "        for t in range(seq.shape[0]):\n",
    "            x = seq[t].reshape(-1,1)\n",
    "            f = self._sigmoid(self.W_f @ x + self.U_f @ h + self.b_f)\n",
    "            i = self._sigmoid(self.W_i @ x + self.U_i @ h + self.b_i)\n",
    "            o = self._sigmoid(self.W_o @ x + self.U_o @ h + self.b_o)\n",
    "            c_hat = np.tanh(self.W_c @ x + self.U_c @ h + self.b_c)\n",
    "            c = f * c + i * c_hat\n",
    "            h = o * np.tanh(c)\n",
    "        return h.flatten()  # (hidden_dim,)\n",
    "\n",
    "# --------------------------\n",
    "# 5) 보조 피처: 평균 임베딩, TF-IDF 가중 평균\n",
    "# --------------------------\n",
    "def mean_glove_vector(tokens, glove, dim=100):\n",
    "    vecs = [glove[t] for t in tokens if t in glove]\n",
    "    if len(vecs) == 0:\n",
    "        return np.zeros(dim, dtype=np.float32)\n",
    "    return np.mean(vecs, axis=0)\n",
    "\n",
    "def tfidf_weighted_avg(texts, glove, dim=100, tfidf=None):\n",
    "    # tfidf: fitted TfidfVectorizer (if None, will fit inside)\n",
    "    if tfidf is None:\n",
    "        tfidf = TfidfVectorizer()\n",
    "        tfidf.fit(texts)\n",
    "    X_tfidf = tfidf.transform(texts)  # sparse\n",
    "    feature_names = tfidf.get_feature_names_out()\n",
    "    # build word->colidx mapping\n",
    "    col_idx = {w:i for i,w in enumerate(feature_names)}\n",
    "    res = []\n",
    "    for doc_idx, txt in enumerate(texts):\n",
    "        tokens = txt.split()\n",
    "        weight_sum = 0.0\n",
    "        vec = np.zeros(dim, dtype=np.float32)\n",
    "        for w in tokens:\n",
    "            if w in col_idx and w in glove:\n",
    "                w_idx = col_idx[w]\n",
    "                weight = X_tfidf[doc_idx, w_idx]\n",
    "                vec += glove[w] * weight\n",
    "                weight_sum += weight\n",
    "        if weight_sum > 0:\n",
    "            vec = vec / weight_sum\n",
    "        res.append(vec)\n",
    "    return np.array(res), tfidf\n",
    "\n",
    "# --------------------------\n",
    "# 6) 전체 파이프라인 함수\n",
    "# --------------------------\n",
    "def build_feature_matrix(texts, glove, lstm_encoder, tfidf=None, dim=100, max_len=30):\n",
    "    texts_clean = [clean_text(t) for t in texts]\n",
    "    tokens_list = [tokenize(t) for t in texts_clean]\n",
    "\n",
    "    # mean glove\n",
    "    mean_vectors = np.array([mean_glove_vector(tokens, glove, dim) for tokens in tokens_list])\n",
    "\n",
    "    # tfidf weighted avg (if tfidf provided, reuse)\n",
    "    tfidf_weighted, tfidf = tfidf_weighted_avg(texts_clean, glove, dim, tfidf=tfidf)\n",
    "\n",
    "    # LSTM last hidden\n",
    "    seqs = [sentence_to_seq(tokens, glove, dim=dim, max_len=max_len) for tokens in tokens_list]\n",
    "    lstm_features = np.array([lstm_encoder.forward(seq) for seq in seqs])  # (N, hidden_dim)\n",
    "\n",
    "    # length feature\n",
    "    lengths = np.array([[len(tokens)] for tokens in tokens_list], dtype=np.float32)\n",
    "\n",
    "    # concatenate features: mean_glove | tfidf_weighted | lstm_hidden | length\n",
    "    X = np.hstack([mean_vectors, tfidf_weighted, lstm_features, lengths])\n",
    "    return X, tfidf\n",
    "\n",
    "# --------------------------\n",
    "# 7) 예시: 실제 데이터 불러와 실행\n",
    "# --------------------------\n",
    "# 파일 이름은 네 환경에 맞게 수정\n",
    "train_df = pd.read_csv(\"train_ready.csv\")\n",
    "dev_df   = pd.read_csv(\"dev_ready.csv\")\n",
    "test_df  = pd.read_csv(\"test_ready.csv\")\n",
    "\n",
    "# combine train+dev for tfidf stability (optional)\n",
    "all_train_texts = (train_df[\"text\"].fillna(\"\").tolist() + dev_df[\"text\"].fillna(\"\").tolist())\n",
    "# load glove\n",
    "EMB_DIM = 100\n",
    "glove = load_glove(\"glove.6B.100d.txt\", dim=EMB_DIM)\n",
    "\n",
    "# LSTM encoder\n",
    "lstm_encoder = NumPyLSTMEncoder(input_dim=EMB_DIM, hidden_dim=64, seed=123)\n",
    "\n",
    "# Build features for train\n",
    "train_texts = train_df[\"text\"].fillna(\"\").tolist()\n",
    "dev_texts = dev_df[\"text\"].fillna(\"\").tolist()\n",
    "test_texts = test_df[\"text\"].fillna(\"\").tolist()\n",
    "\n",
    "# fit TF-IDF on train+dev for more stable idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=1)\n",
    "tfidf.fit(all_train_texts)\n",
    "\n",
    "X_train, _ = build_feature_matrix(train_texts, glove, lstm_encoder, tfidf=tfidf, dim=EMB_DIM, max_len=30)\n",
    "X_dev, _   = build_feature_matrix(dev_texts, glove, lstm_encoder, tfidf=tfidf, dim=EMB_DIM, max_len=30)\n",
    "X_test, _  = build_feature_matrix(test_texts, glove, lstm_encoder, tfidf=tfidf, dim=EMB_DIM, max_len=30)\n",
    "\n",
    "y_train = train_df[\"label\"].astype(int).values\n",
    "y_dev   = dev_df[\"label\"].astype(int).values\n",
    "y_test  = test_df[\"label\"].astype(int).values\n",
    "\n",
    "# --------------------------\n",
    "# 8) 스케일링 / 차원축소 (선택)\n",
    "# --------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_dev_s = scaler.transform(X_dev)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "# (선택) PCA로 차원 줄이기 — 안정성 필요하면 사용\n",
    "# pca = PCA(n_components=0.95)\n",
    "# X_train_s = pca.fit_transform(X_train_s)\n",
    "# X_dev_s = pca.transform(X_dev_s)\n",
    "# X_test_s = pca.transform(X_test_s)\n",
    "\n",
    "# --------------------------\n",
    "# 9) SVM 학습 및 평가\n",
    "# --------------------------\n",
    "svm = SVC(kernel=\"linear\", probability=True, class_weight=\"balanced\")\n",
    "svm.fit(X_train_s, y_train)\n",
    "\n",
    "def evaluate_model(model, X, y, name=\"\"):\n",
    "    preds = model.predict(X)\n",
    "    probs = None\n",
    "    try:\n",
    "        probs = model.predict_proba(X)[:,1]\n",
    "    except:\n",
    "        pass\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(\"Accuracy:\", accuracy_score(y, preds))\n",
    "    print(\"F1:\", f1_score(y, preds, zero_division=0))\n",
    "    print(classification_report(y, preds, zero_division=0))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y, preds))\n",
    "\n",
    "evaluate_model(svm, X_train_s, y_train, \"Train\")\n",
    "evaluate_model(svm, X_dev_s, y_dev, \"Dev\")\n",
    "evaluate_model(svm, X_test_s, y_test, \"Test\")\n",
    "\n",
    "# --------------------------\n",
    "# 10) 저장 (모델, scaler, tfidf)\n",
    "# --------------------------\n",
    "import joblib\n",
    "joblib.dump(svm, \"svm_glove_lstm_svm.pkl\")\n",
    "joblib.dump(scaler, \"scaler_glove_lstm.pkl\")\n",
    "joblib.dump(tfidf, \"tfidf_glove.pkl\")\n",
    "print(\"저장 완료: svm_glove_lstm_svm.pkl, scaler_glove_lstm.pkl, tfidf_glove.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fe2586",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "전체 결과를 보면 훈련은 완전 과적합(accuracy 1.0), Dev·Test는 중간 정도 성능(0.8 → 0.66)\n",
    "즉, 모델 구조 자체는 정상적으로 동작했지만 데이터 적음 + LSTM 단순화 + SVM 조합의 한계 + 과적합 때문에 이런 결과가 나옴\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bbd4efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe loaded: 400000\n",
      "Best Params: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "=== Dev 성능 ===\n",
      "Accuracy: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         SLI       0.00      0.00      0.00         7\n",
      "          TD       0.80      1.00      0.89        28\n",
      "\n",
      "    accuracy                           0.80        35\n",
      "   macro avg       0.40      0.50      0.44        35\n",
      "weighted avg       0.64      0.80      0.71        35\n",
      "\n",
      "\n",
      "=== Test 성능 ===\n",
      "Accuracy: 0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         SLI       0.00      0.00      0.00         6\n",
      "          TD       0.83      1.00      0.91        30\n",
      "\n",
      "    accuracy                           0.83        36\n",
      "   macro avg       0.42      0.50      0.45        36\n",
      "weighted avg       0.69      0.83      0.76        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import re\n",
    "\n",
    "train_df = pd.read_csv(\"ENNI_train.csv\")\n",
    "dev_df   = pd.read_csv(\"ENNI_dev.csv\")\n",
    "test_df  = pd.read_csv(\"ENNI_test.csv\")\n",
    "\n",
    "# 텍스트 파일(.cha → txt 전처리 완료되어 있다고 가정)\n",
    "train_files = train_df[\"filename\"].tolist()\n",
    "dev_files   = dev_df[\"filename\"].tolist()\n",
    "test_files  = test_df[\"filename\"].tolist()\n",
    "\n",
    "train_y = train_df[\"group\"].tolist()\n",
    "dev_y   = dev_df[\"group\"].tolist()\n",
    "test_y  = test_df[\"group\"].tolist()\n",
    "\n",
    "def load_cha_text(filepath):\n",
    "    lines = []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"*CHI\"):  # 아동 발화만 사용 (기본 ENNI 관례)\n",
    "                clean = re.sub(r\"[^\\w\\s']\", \" \", line)\n",
    "                clean = re.sub(r\"\\s+\", \" \", clean).strip()\n",
    "                lines.append(clean.lower())\n",
    "    return \" \".join(lines)\n",
    "\n",
    "def load_glove(glove_path=\"glove.6B.300d.txt\"):\n",
    "    glove = {}\n",
    "    with open(glove_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            word = parts[0]\n",
    "            vec = np.array(parts[1:], dtype=\"float32\")\n",
    "            glove[word] = vec\n",
    "    print(\"GloVe loaded:\", len(glove))\n",
    "    return glove\n",
    "\n",
    "glove = load_glove()\n",
    "\n",
    "class NumPyLSTM:\n",
    "    def __init__(self, input_dim=300, hidden_dim=128):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        h = hidden_dim\n",
    "        d = input_dim\n",
    "        \n",
    "        # Xavier 초기화\n",
    "        self.Wf = np.random.randn(h, h + d) / np.sqrt(h + d)\n",
    "        self.Wi = np.random.randn(h, h + d) / np.sqrt(h + d)\n",
    "        self.Wc = np.random.randn(h, h + d) / np.sqrt(h + d)\n",
    "        self.Wo = np.random.randn(h, h + d) / np.sqrt(h + d)\n",
    "        \n",
    "    def step(self, x, h_prev, c_prev):\n",
    "        z = np.concatenate([h_prev, x])  # [hidden_dim + input_dim]\n",
    "\n",
    "        f = self.sigmoid(self.Wf @ z)\n",
    "        i = self.sigmoid(self.Wi @ z)\n",
    "        c_hat = np.tanh(self.Wc @ z)\n",
    "        c = f * c_prev + i * c_hat\n",
    "        o = self.sigmoid(self.Wo @ z)\n",
    "        h = o * np.tanh(c)\n",
    "\n",
    "        return h, c\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def encode(self, seq):\n",
    "        h = np.zeros(self.hidden_dim)\n",
    "        c = np.zeros(self.hidden_dim)\n",
    "        for x in seq:\n",
    "            h, c = self.step(x, h, c)\n",
    "        return h\n",
    "\n",
    "lstm = NumPyLSTM()\n",
    "\n",
    "def sentence_to_glove_seq(text, glove):\n",
    "    seq = []\n",
    "    for w in text.split():\n",
    "        if w in glove:\n",
    "            seq.append(glove[w])\n",
    "    if len(seq) == 0:  # 빈 문장 방지\n",
    "        seq.append(np.zeros(300))\n",
    "    return seq\n",
    "\n",
    "def encode_file(filepath, glove, lstm):\n",
    "    text = load_cha_text(filepath)\n",
    "    seq = sentence_to_glove_seq(text, glove)\n",
    "    return lstm.encode(seq)\n",
    "\n",
    "def encode_dataset(file_list, glove, lstm):\n",
    "    vectors = []\n",
    "    for f in file_list:\n",
    "        vec = encode_file(f, glove, lstm)\n",
    "        vectors.append(vec)\n",
    "    return np.array(vectors)\n",
    "\n",
    "train_vec = encode_dataset(train_files, glove, lstm)\n",
    "dev_vec   = encode_dataset(dev_files, glove, lstm)\n",
    "test_vec  = encode_dataset(test_files, glove, lstm)\n",
    "\n",
    "def train_and_evaluate(train_x, train_y, dev_x, dev_y, test_x, test_y):\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    train_x = scaler.fit_transform(train_x)\n",
    "    dev_x   = scaler.transform(dev_x)\n",
    "    test_x  = scaler.transform(test_x)\n",
    "\n",
    "    # SVM + Grid Search\n",
    "    params = {\n",
    "        \"C\": [0.1, 1, 10],\n",
    "        \"kernel\": [\"linear\", \"rbf\"],\n",
    "        \"gamma\": [\"scale\", \"auto\"]\n",
    "    }\n",
    "\n",
    "    svm = SVC()\n",
    "    clf = GridSearchCV(svm, params, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "    clf.fit(train_x, train_y)\n",
    "\n",
    "    print(\"Best Params:\", clf.best_params_)\n",
    "\n",
    "    print(\"\\n=== Dev 성능 ===\")\n",
    "    pred_dev = clf.predict(dev_x)\n",
    "    print(\"Accuracy:\", accuracy_score(dev_y, pred_dev))\n",
    "    print(classification_report(dev_y, pred_dev))\n",
    "\n",
    "    print(\"\\n=== Test 성능 ===\")\n",
    "    pred_test = clf.predict(test_x)\n",
    "    print(\"Accuracy:\", accuracy_score(test_y, pred_test))\n",
    "    print(classification_report(test_y, pred_test))\n",
    "\n",
    "    return clf, scaler\n",
    "\n",
    "clf, scaler = train_and_evaluate(train_vec, train_y, dev_vec, dev_y, test_vec, test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c8d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"모델이 SLI를 단 1개도 예측하지 않음\n",
    "\n",
    "→ Dev/Test에서 SLI precision, recall, F1 = 0\n",
    "\n",
    "왜 이렇게 됐는가?\n",
    "1) 데이터 라벨 비율이 극단적으로 불균형\n",
    "\n",
    "ENNI는 보통 TD가 훨씬 많고 SLI가 적음.\n",
    "→ 단순 SVM은 “TD만 찍어도 정확도는 높음” 따라서 그 방향으로 학습함.\n",
    "\n",
    "2) GloVe + NumPy LSTM 인코더의 표현력이 낮음\n",
    "\n",
    "아동 발화는 짧고 문법이 깨져 있음\n",
    "\n",
    "GloVe는 adult corpus 기반\n",
    "\n",
    "NumPy LSTM은 학습되지 않은 랜덤 가중치(=feature extractor quality 낮음)\n",
    "\n",
    "→ 모델이 SLI의 특징을 전혀 분리 못함.\n",
    "\n",
    "3) 선형/비선형 SVM은 imbalance 보정 없으면 collapse 발생\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "062dcc1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe loaded: 400000\n",
      "Best Params: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'linear'}\n",
      "\n",
      "=== Dev 성능 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         SLI       0.27      0.57      0.36         7\n",
      "          TD       0.85      0.61      0.71        28\n",
      "\n",
      "    accuracy                           0.60        35\n",
      "   macro avg       0.56      0.59      0.54        35\n",
      "weighted avg       0.73      0.60      0.64        35\n",
      "\n",
      "[[ 4  3]\n",
      " [11 17]]\n",
      "\n",
      "=== Test 성능 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         SLI       0.24      0.67      0.35         6\n",
      "          TD       0.89      0.57      0.69        30\n",
      "\n",
      "    accuracy                           0.58        36\n",
      "   macro avg       0.57      0.62      0.52        36\n",
      "weighted avg       0.78      0.58      0.64        36\n",
      "\n",
      "[[ 4  2]\n",
      " [13 17]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import re\n",
    "\n",
    "train_df = pd.read_csv(\"ENNI_train.csv\")\n",
    "dev_df   = pd.read_csv(\"ENNI_dev.csv\")\n",
    "test_df  = pd.read_csv(\"ENNI_test.csv\")\n",
    "\n",
    "# 텍스트 파일(.cha → txt 전처리 완료되어 있다고 가정)\n",
    "train_files = train_df[\"filename\"].tolist()\n",
    "dev_files   = dev_df[\"filename\"].tolist()\n",
    "test_files  = test_df[\"filename\"].tolist()\n",
    "\n",
    "train_y = train_df[\"group\"].tolist()\n",
    "dev_y   = dev_df[\"group\"].tolist()\n",
    "test_y  = test_df[\"group\"].tolist()\n",
    "\n",
    "def load_cha_text(filepath):\n",
    "    lines = []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"*CHI\"):  # 아동 발화만 사용 (기본 ENNI 관례)\n",
    "                clean = re.sub(r\"[^\\w\\s']\", \" \", line)\n",
    "                clean = re.sub(r\"\\s+\", \" \", clean).strip()\n",
    "                lines.append(clean.lower())\n",
    "    return \" \".join(lines)\n",
    "\n",
    "def load_glove(glove_path=\"glove.6B.300d.txt\"):\n",
    "    glove = {}\n",
    "    with open(glove_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            word = parts[0]\n",
    "            vec = np.array(parts[1:], dtype=\"float32\")\n",
    "            glove[word] = vec\n",
    "    print(\"GloVe loaded:\", len(glove))\n",
    "    return glove\n",
    "\n",
    "glove = load_glove()\n",
    "\n",
    "class NumPyLSTM:\n",
    "    def __init__(self, input_dim=300, hidden_dim=128):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        h = hidden_dim\n",
    "        d = input_dim\n",
    "        \n",
    "        # Xavier 초기화\n",
    "        self.Wf = np.random.randn(h, h + d) / np.sqrt(h + d)\n",
    "        self.Wi = np.random.randn(h, h + d) / np.sqrt(h + d)\n",
    "        self.Wc = np.random.randn(h, h + d) / np.sqrt(h + d)\n",
    "        self.Wo = np.random.randn(h, h + d) / np.sqrt(h + d)\n",
    "        \n",
    "    def step(self, x, h_prev, c_prev):\n",
    "        z = np.concatenate([h_prev, x])  # [hidden_dim + input_dim]\n",
    "\n",
    "        f = self.sigmoid(self.Wf @ z)\n",
    "        i = self.sigmoid(self.Wi @ z)\n",
    "        c_hat = np.tanh(self.Wc @ z)\n",
    "        c = f * c_prev + i * c_hat\n",
    "        o = self.sigmoid(self.Wo @ z)\n",
    "        h = o * np.tanh(c)\n",
    "\n",
    "        return h, c\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def encode(self, seq):\n",
    "        h = np.zeros(self.hidden_dim)\n",
    "        c = np.zeros(self.hidden_dim)\n",
    "        for x in seq:\n",
    "            h, c = self.step(x, h, c)\n",
    "        return h\n",
    "\n",
    "lstm = NumPyLSTM()\n",
    "\n",
    "def sentence_to_glove_seq(text, glove):\n",
    "    seq = []\n",
    "    for w in text.split():\n",
    "        if w in glove:\n",
    "            seq.append(glove[w])\n",
    "    if len(seq) == 0:  # 빈 문장 방지\n",
    "        seq.append(np.zeros(300))\n",
    "    return seq\n",
    "\n",
    "def encode_file(filepath, glove, lstm):\n",
    "    text = load_cha_text(filepath)\n",
    "    seq = sentence_to_glove_seq(text, glove)\n",
    "    return lstm.encode(seq)\n",
    "\n",
    "def encode_dataset(file_list, glove, lstm):\n",
    "    vectors = []\n",
    "    for f in file_list:\n",
    "        vec = encode_file(f, glove, lstm)\n",
    "        vectors.append(vec)\n",
    "    return np.array(vectors)\n",
    "\n",
    "train_vec = encode_dataset(train_files, glove, lstm)\n",
    "dev_vec   = encode_dataset(dev_files, glove, lstm)\n",
    "test_vec  = encode_dataset(test_files, glove, lstm)\n",
    "\n",
    "def train_and_eval(train_x, train_y, dev_x, dev_y, test_x, test_y):\n",
    "\n",
    "    # 🔹 GridSearchCV 파라미터에 class_weight='balanced' 추가\n",
    "    params = {\n",
    "        \"C\": [0.1, 1, 10],\n",
    "        \"kernel\": [\"linear\", \"rbf\"],\n",
    "        \"gamma\": [\"scale\", \"auto\"],\n",
    "        \"class_weight\": [\"balanced\"]   # ⭐ 핵심 추가\n",
    "    }\n",
    "\n",
    "    svm = SVC()\n",
    "    clf = GridSearchCV(\n",
    "        svm,\n",
    "        params,\n",
    "        cv=3,\n",
    "        scoring='f1_macro',    # 불균형일 때 macro f1이 더 적절\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    clf.fit(train_x, train_y)\n",
    "\n",
    "    print(\"Best Params:\", clf.best_params_)\n",
    "    best_model = clf.best_estimator_\n",
    "\n",
    "    print(\"\\n=== Dev 성능 ===\")\n",
    "    dev_pred = best_model.predict(dev_x)\n",
    "    print(classification_report(dev_y, dev_pred))\n",
    "    print(confusion_matrix(dev_y, dev_pred))\n",
    "\n",
    "    print(\"\\n=== Test 성능 ===\")\n",
    "    test_pred = best_model.predict(test_x)\n",
    "    print(classification_report(test_y, test_pred))\n",
    "    print(confusion_matrix(test_y, test_pred))\n",
    "\n",
    "    return best_model\n",
    "clf = train_and_eval(train_vec, train_y, dev_vec, dev_y, test_vec, test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6a3880",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LI recall이 0% → 67%로 폭증\n",
    "\n",
    "Dev: SLI recall 57%\n",
    "\n",
    "Test: SLI recall 67%\n",
    "\n",
    "즉, **SLI를 실제로 '잡기 시작'**했어.\n",
    "이건 불균형 데이터 개선에서 반드시 필요한 핵심 변화임.\n",
    "\n",
    "❌ 하지만 TD 성능이 떨어짐\n",
    "\n",
    "TD recall이 100 → 57로 감소\n",
    "\n",
    "Accuracy도 0.8 → 0.58로 내려감\n",
    "\n",
    "즉, 모델이 SLI를 잡는 대신 TD를 SLI로 더 오판하는 방향\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1fab68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading GloVe: 400000it [00:17, 22491.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe loaded: 400000\n",
      "스케일러 적용 중...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Best Params: {'C': 0.01, 'gamma': 'scale'}\n",
      "\n",
      "=== Dev 성능 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         SLI       0.20      1.00      0.33         7\n",
      "          TD       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.20        35\n",
      "   macro avg       0.10      0.50      0.17        35\n",
      "weighted avg       0.04      0.20      0.07        35\n",
      "\n",
      "[[ 7  0]\n",
      " [28  0]]\n",
      "\n",
      "=== Test 성능 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         SLI       0.17      1.00      0.29         6\n",
      "          TD       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.17        36\n",
      "   macro avg       0.08      0.50      0.14        36\n",
      "weighted avg       0.03      0.17      0.05        36\n",
      "\n",
      "[[ 6  0]\n",
      " [30  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jeonginn/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w5/1h0crrlj5hx238pnm9g4gcgw0000gn/T/ipykernel_72955/1328942489.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;31m# SVM 학습 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m svm_model, scaler, params = train_svm_balanced(\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0mtrain_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mdev_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/w5/1h0crrlj5hx238pnm9g4gcgw0000gn/T/ipykernel_72955/1328942489.py\u001b[0m in \u001b[0;36mtrain_svm_balanced\u001b[0;34m(train_x, train_y, dev_x, dev_y, test_x, test_y)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_svm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params__'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................C=0.01, gamma=auto; total time=   2.5s\n",
      "[CV] END .................................C=0.01, gamma=auto; total time=   0.0s\n",
      "[CV] END .................................C=0.01, gamma=auto; total time=   0.0s\n",
      "[CV] END .................................C=0.1, gamma=scale; total time=   0.0s\n",
      "[CV] END .................................C=0.1, gamma=scale; total time=   0.0s\n",
      "[CV] END .................................C=0.1, gamma=scale; total time=   0.0s\n",
      "[CV] END .................................C=0.1, gamma=scale; total time=   0.0s\n",
      "[CV] END .................................C=0.1, gamma=scale; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, gamma=auto; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, gamma=auto; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, gamma=auto; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, gamma=auto; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, gamma=auto; total time=   0.0s\n",
      "[CV] END ...................................C=1, gamma=scale; total time=   0.0s\n",
      "[CV] END ...................................C=1, gamma=scale; total time=   0.0s\n",
      "[CV] END ...................................C=1, gamma=scale; total time=   0.0s\n",
      "[CV] END ...................................C=1, gamma=scale; total time=   0.0s\n",
      "[CV] END ...................................C=1, gamma=scale; total time=   0.0s\n",
      "[CV] END ....................................C=1, gamma=auto; total time=   0.0s\n",
      "[CV] END ....................................C=1, gamma=auto; total time=   0.0s\n",
      "[CV] END ....................................C=1, gamma=auto; total time=   0.0s\n",
      "[CV] END ....................................C=1, gamma=auto; total time=   0.0s\n",
      "[CV] END ....................................C=1, gamma=auto; total time=   0.0s\n",
      "[CV] END ..................................C=10, gamma=scale; total time=   0.0s\n",
      "[CV] END ..................................C=10, gamma=scale; total time=   0.0s\n",
      "[CV] END ...................................C=10, gamma=auto; total time=   0.0s\n",
      "[CV] END ................................C=0.01, gamma=scale; total time=   2.8s\n",
      "[CV] END ..................................C=10, gamma=scale; total time=   0.0s\n",
      "[CV] END ..................................C=10, gamma=scale; total time=   0.0s\n",
      "[CV] END ...................................C=10, gamma=auto; total time=   0.0s\n",
      "[CV] END .................................C=0.01, gamma=auto; total time=   2.8s\n",
      "[CV] END .................................C=0.01, gamma=auto; total time=   2.8s\n",
      "[CV] END ...................................C=10, gamma=auto; total time=   0.0s\n",
      "[CV] END ................................C=0.01, gamma=scale; total time=   2.8s\n",
      "[CV] END ...................................C=10, gamma=auto; total time=   0.0s\n",
      "[CV] END ................................C=0.01, gamma=scale; total time=   2.7s\n",
      "[CV] END ..................................C=10, gamma=scale; total time=   0.0s\n",
      "[CV] END ...................................C=10, gamma=auto; total time=   0.0s\n",
      "[CV] END ................................C=0.01, gamma=scale; total time=   2.8s\n",
      "[CV] END ................................C=0.01, gamma=scale; total time=   2.8s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# =========================\n",
    "# 1. GloVe 로드\n",
    "# =========================\n",
    "def load_glove(glove_path):\n",
    "    embeddings = {}\n",
    "    with open(glove_path, \"r\", encoding=\"utf8\") as f:\n",
    "        for line in tqdm(f, desc=\"Loading GloVe\"):\n",
    "            values = line.rstrip().split(\" \")\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2. 전처리 및 문장 → 임베딩 변환\n",
    "# =========================\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
    "    return text.split()\n",
    "\n",
    "def sentence_to_embedding(sentence, glove, dim=300):\n",
    "    tokens = preprocess(sentence)\n",
    "    vecs = [glove[t] for t in tokens if t in glove]\n",
    "    if len(vecs) == 0:\n",
    "        return np.zeros((1, dim))\n",
    "    return np.array(vecs)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3. NumPy LSTM Encoder\n",
    "# =========================\n",
    "class NumpyLSTM:\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.Wf = np.random.randn(hidden_dim, input_dim + hidden_dim) * 0.1\n",
    "        self.bf = np.zeros((hidden_dim, 1))\n",
    "\n",
    "        self.Wi = np.random.randn(hidden_dim, input_dim + hidden_dim) * 0.1\n",
    "        self.bi = np.zeros((hidden_dim, 1))\n",
    "\n",
    "        self.Wc = np.random.randn(hidden_dim, input_dim + hidden_dim) * 0.1\n",
    "        self.bc = np.zeros((hidden_dim, 1))\n",
    "\n",
    "        self.Wo = np.random.randn(hidden_dim, input_dim + hidden_dim) * 0.1\n",
    "        self.bo = np.zeros((hidden_dim, 1))\n",
    "\n",
    "    def step(self, x, h_prev, c_prev):\n",
    "        concat = np.vstack((h_prev, x))\n",
    "\n",
    "        f = self.sigmoid(self.Wf @ concat + self.bf)\n",
    "        i = self.sigmoid(self.Wi @ concat + self.bi)\n",
    "        c_hat = np.tanh(self.Wc @ concat + self.bc)\n",
    "        c = f * c_prev + i * c_hat\n",
    "        o = self.sigmoid(self.Wo @ concat + self.bo)\n",
    "        h = o * np.tanh(c)\n",
    "        return h, c\n",
    "\n",
    "    def encode(self, sequence):\n",
    "        h = np.zeros((self.hidden_dim, 1))\n",
    "        c = np.zeros((self.hidden_dim, 1))\n",
    "        for word_vec in sequence:\n",
    "            x = word_vec.reshape(-1, 1)\n",
    "            h, c = self.step(x, h, c)\n",
    "        return h.reshape(-1)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4. Dataset → 벡터로 변환\n",
    "# =========================\n",
    "def encode_dataset(texts, glove, lstm):\n",
    "    vectors = []\n",
    "    for sent in texts:\n",
    "        seq = sentence_to_embedding(sent, glove)\n",
    "        h = lstm.encode(seq)\n",
    "        vectors.append(h)\n",
    "    return np.array(vectors)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5. SVM 학습 (rbf 고정 + balanced)\n",
    "# =========================\n",
    "def train_svm_balanced(train_x, train_y, dev_x, dev_y, test_x, test_y):\n",
    "\n",
    "    print(\"스케일러 적용 중...\")\n",
    "    scaler = StandardScaler()\n",
    "    train_x = scaler.fit_transform(train_x)\n",
    "    dev_x = scaler.transform(dev_x)\n",
    "    test_x = scaler.transform(test_x)\n",
    "\n",
    "    # GridSearch: rbf 커널 고정\n",
    "    param_grid = {\n",
    "        \"C\": [0.01, 0.1, 1, 10],\n",
    "        \"gamma\": [\"scale\", \"auto\"]\n",
    "    }\n",
    "\n",
    "    svm = SVC(\n",
    "        kernel=\"rbf\",\n",
    "        class_weight=\"balanced\"\n",
    "    )\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        svm,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    grid.fit(train_x, train_y)\n",
    "\n",
    "    print(\"\\nBest Params:\", grid.best_params_)\n",
    "    best_svm = grid.best_estimator_\n",
    "\n",
    "    # -------------------\n",
    "    print(\"\\n=== Dev 성능 ===\")\n",
    "    pred_dev = best_svm.predict(dev_x)\n",
    "    print(classification_report(dev_y, pred_dev))\n",
    "    print(confusion_matrix(dev_y, pred_dev))\n",
    "\n",
    "    # -------------------\n",
    "    print(\"\\n=== Test 성능 ===\")\n",
    "    pred_test = best_svm.predict(test_x)\n",
    "    print(classification_report(test_y, pred_test))\n",
    "    print(confusion_matrix(test_y, pred_test))\n",
    "\n",
    "    return best_svm, scaler, grid.best_params__\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 6. 실제 실행\n",
    "# =========================\n",
    "\n",
    "glove_path = \"glove.6B.300d.txt\"\n",
    "glove = load_glove(glove_path)\n",
    "print(\"GloVe loaded:\", len(glove))\n",
    "\n",
    "# LSTM 인코더\n",
    "lstm = NumpyLSTM(input_dim=300, hidden_dim=128)\n",
    "\n",
    "# 텍스트 → 벡터\n",
    "train_vec = encode_dataset(train_texts, glove, lstm)\n",
    "dev_vec   = encode_dataset(dev_texts, glove, lstm)\n",
    "test_vec  = encode_dataset(test_texts, glove, lstm)\n",
    "\n",
    "# SVM 학습 실행\n",
    "svm_model, scaler, params = train_svm_balanced(\n",
    "    train_vec, train_y,\n",
    "    dev_vec, dev_y,\n",
    "    test_vec, test_y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b99018b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading GloVe: 400000it [00:17, 22343.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe loaded: 400000\n",
      "스케일러 적용 중...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Best Params: {'C': 10, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'linear'}\n",
      "\n",
      "=== Dev 성능 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         SLI       0.33      0.43      0.38         7\n",
      "          TD       0.85      0.79      0.81        28\n",
      "\n",
      "    accuracy                           0.71        35\n",
      "   macro avg       0.59      0.61      0.59        35\n",
      "weighted avg       0.74      0.71      0.73        35\n",
      "\n",
      "[[ 3  4]\n",
      " [ 6 22]]\n",
      "\n",
      "=== Test 성능 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         SLI       0.10      0.17      0.12         6\n",
      "          TD       0.81      0.70      0.75        30\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.45      0.43      0.44        36\n",
      "weighted avg       0.69      0.61      0.65        36\n",
      "\n",
      "[[ 1  5]\n",
      " [ 9 21]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# =========================\n",
    "# 1. GloVe 로드\n",
    "# =========================\n",
    "def load_glove(glove_path):\n",
    "    embeddings = {}\n",
    "    with open(glove_path, \"r\", encoding=\"utf8\") as f:\n",
    "        for line in tqdm(f, desc=\"Loading GloVe\"):\n",
    "            values = line.rstrip().split(\" \")\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2. 전처리 및 문장 → 임베딩 변환\n",
    "# =========================\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
    "    return text.split()\n",
    "\n",
    "def sentence_to_embedding(sentence, glove, dim=300):\n",
    "    tokens = preprocess(sentence)\n",
    "    vecs = [glove[t] for t in tokens if t in glove]\n",
    "    if len(vecs) == 0:\n",
    "        return np.zeros((1, dim))\n",
    "    return np.array(vecs)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3. NumPy LSTM Encoder\n",
    "# =========================\n",
    "class NumpyLSTM:\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.Wf = np.random.randn(hidden_dim, input_dim + hidden_dim) * 0.1\n",
    "        self.bf = np.zeros((hidden_dim, 1))\n",
    "\n",
    "        self.Wi = np.random.randn(hidden_dim, input_dim + hidden_dim) * 0.1\n",
    "        self.bi = np.zeros((hidden_dim, 1))\n",
    "\n",
    "        self.Wc = np.random.randn(hidden_dim, input_dim + hidden_dim) * 0.1\n",
    "        self.bc = np.zeros((hidden_dim, 1))\n",
    "\n",
    "        self.Wo = np.random.randn(hidden_dim, input_dim + hidden_dim) * 0.1\n",
    "        self.bo = np.zeros((hidden_dim, 1))\n",
    "\n",
    "    def step(self, x, h_prev, c_prev):\n",
    "        concat = np.vstack((h_prev, x))\n",
    "\n",
    "        f = self.sigmoid(self.Wf @ concat + self.bf)\n",
    "        i = self.sigmoid(self.Wi @ concat + self.bi)\n",
    "        c_hat = np.tanh(self.Wc @ concat + self.bc)\n",
    "        c = f * c_prev + i * c_hat\n",
    "        o = self.sigmoid(self.Wo @ concat + self.bo)\n",
    "        h = o * np.tanh(c)\n",
    "        return h, c\n",
    "\n",
    "    def encode(self, sequence):\n",
    "        h = np.zeros((self.hidden_dim, 1))\n",
    "        c = np.zeros((self.hidden_dim, 1))\n",
    "        for word_vec in sequence:\n",
    "            x = word_vec.reshape(-1, 1)\n",
    "            h, c = self.step(x, h, c)\n",
    "        return h.reshape(-1)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4. Dataset → 벡터로 변환\n",
    "# =========================\n",
    "def encode_dataset(texts, glove, lstm):\n",
    "    vectors = []\n",
    "    for sent in texts:\n",
    "        seq = sentence_to_embedding(sent, glove)\n",
    "        h = lstm.encode(seq)\n",
    "        vectors.append(h)\n",
    "    return np.array(vectors)\n",
    "\n",
    "# --------------------------------------------\n",
    "# SVM 학습 함수 (개선된 version a)\n",
    "# --------------------------------------------\n",
    "def train_svm_balanced(train_x, train_y, dev_x, dev_y, test_x, test_y):\n",
    "    print(\"스케일러 적용 중...\")\n",
    "    scaler = StandardScaler()\n",
    "    train_x = scaler.fit_transform(train_x)\n",
    "    dev_x   = scaler.transform(dev_x)\n",
    "    test_x  = scaler.transform(test_x)\n",
    "\n",
    "    # GridSearch 범위 확장 (collapse 방지)\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 3, 10],\n",
    "        'kernel': ['linear'],\n",
    "        'gamma': ['scale'],\n",
    "        'class_weight': ['balanced']\n",
    "    }\n",
    "\n",
    "    svm = SVC()\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        svm,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring='f1_macro',\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid.fit(train_x, train_y)\n",
    "\n",
    "    print(\"\\nBest Params:\", grid.best_params_)\n",
    "\n",
    "    best_svm = grid.best_estimator_\n",
    "\n",
    "    # ----------------------------\n",
    "    # Dev 성능\n",
    "    # ----------------------------\n",
    "    print(\"\\n=== Dev 성능 ===\")\n",
    "    pred_dev = best_svm.predict(dev_x)\n",
    "    print(classification_report(dev_y, pred_dev))\n",
    "    print(confusion_matrix(dev_y, pred_dev))\n",
    "\n",
    "    # ----------------------------\n",
    "    # Test 성능\n",
    "    # ----------------------------\n",
    "    print(\"\\n=== Test 성능 ===\")\n",
    "    pred_test = best_svm.predict(test_x)\n",
    "    print(classification_report(test_y, pred_test))\n",
    "    print(confusion_matrix(test_y, pred_test))\n",
    "\n",
    "    return best_svm, scaler, grid.best_params_\n",
    "\n",
    "# =========================\n",
    "# 6. 실제 실행\n",
    "# =========================\n",
    "\n",
    "glove_path = \"glove.6B.300d.txt\"\n",
    "glove = load_glove(glove_path)\n",
    "print(\"GloVe loaded:\", len(glove))\n",
    "\n",
    "# LSTM 인코더\n",
    "lstm = NumpyLSTM(input_dim=300, hidden_dim=128)\n",
    "\n",
    "# 텍스트 → 벡터\n",
    "train_vec = encode_dataset(train_texts, glove, lstm)\n",
    "dev_vec   = encode_dataset(dev_texts, glove, lstm)\n",
    "test_vec  = encode_dataset(test_texts, glove, lstm)\n",
    "\n",
    "# SVM 학습 실행\n",
    "svm_model, scaler, params = train_svm_balanced(\n",
    "    train_vec, train_y,\n",
    "    dev_vec, dev_y,\n",
    "    test_vec, test_y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1765e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "지금 결과에서 문제점 요약\n",
    "✔ TD(다수 클래스)는 잘 맞춘다\n",
    "\n",
    "Dev F1: 0.81\n",
    "\n",
    "Test F1: 0.75\n",
    "\n",
    "❗ SLI(소수 클래스) Recall이 낮다\n",
    "\n",
    "Dev Recall: 0.43\n",
    "\n",
    "Test Recall: 0.17\n",
    "\n",
    "즉, SLI를 더 많이 잡아내도록 모델 편향을 보정해야 함.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61e1697e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 400000/400000 [00:17<00:00, 22526.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe loaded: 400000\n",
      "스케일러 적용 중...\n",
      "\n",
      "Best Params: {'C': 50, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "=== Dev 성능 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         SLI       0.00      0.00      0.00         7\n",
      "          TD       0.78      0.89      0.83        28\n",
      "\n",
      "    accuracy                           0.71        35\n",
      "   macro avg       0.39      0.45      0.42        35\n",
      "weighted avg       0.62      0.71      0.67        35\n",
      "\n",
      "[[ 0  7]\n",
      " [ 3 25]]\n",
      "\n",
      "=== Test 성능 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         SLI       0.43      0.50      0.46         6\n",
      "          TD       0.90      0.87      0.88        30\n",
      "\n",
      "    accuracy                           0.81        36\n",
      "   macro avg       0.66      0.68      0.67        36\n",
      "weighted avg       0.82      0.81      0.81        36\n",
      "\n",
      "[[ 3  3]\n",
      " [ 4 26]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 1. GloVe 불러오기\n",
    "# ================================\n",
    "def load_glove(path):\n",
    "    glove = {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, total=400000):\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vec = np.asarray(values[1:], dtype='float32')\n",
    "            glove[word] = vec\n",
    "    print(\"GloVe loaded:\", len(glove))\n",
    "    return glove\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 2. 간단한 NumPy LSTM 구현\n",
    "# ================================\n",
    "class NumpyLSTM:\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.W = np.random.randn(input_dim + hidden_dim, 4 * hidden_dim) * 0.1\n",
    "        self.b = np.zeros((4 * hidden_dim,))\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = np.zeros((self.hidden_dim,))\n",
    "        c = np.zeros((self.hidden_dim,))\n",
    "        for t in range(x.shape[0]):\n",
    "            xt = x[t]\n",
    "            concat = np.concatenate([h, xt])\n",
    "            gates = concat @ self.W + self.b\n",
    "\n",
    "            i = 1 / (1 + np.exp(-gates[:self.hidden_dim]))         # input gate\n",
    "            f = 1 / (1 + np.exp(-gates[self.hidden_dim:2*self.hidden_dim]))  # forget gate\n",
    "            o = 1 / (1 + np.exp(-gates[2*self.hidden_dim:3*self.hidden_dim])) # output gate\n",
    "            g = np.tanh(gates[3*self.hidden_dim:])                          # candidate\n",
    "\n",
    "            c = f * c + i * g\n",
    "            h = o * np.tanh(c)\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 3. 텍스트 → GloVe → LSTM 인코딩\n",
    "# ================================\n",
    "def encode_sentence(text, glove, lstm, max_len=50):\n",
    "    tokens = text.lower().split()\n",
    "    vecs = []\n",
    "\n",
    "    for tok in tokens[:max_len]:\n",
    "        if tok in glove:\n",
    "            vecs.append(glove[tok])\n",
    "        else:\n",
    "            vecs.append(np.zeros((300,)))\n",
    "\n",
    "    if len(vecs) == 0:\n",
    "        vecs.append(np.zeros((300,)))\n",
    "\n",
    "    return lstm.forward(np.array(vecs))\n",
    "\n",
    "\n",
    "def encode_dataset(texts, glove, lstm):\n",
    "    return np.array([encode_sentence(t, glove, lstm) for t in texts])\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 4. SVM(RBF 중심) + class_weight=balanced 탐색\n",
    "# ================================\n",
    "def train_svm_rbf(train_x, train_y, dev_x, dev_y, test_x, test_y):\n",
    "\n",
    "    print(\"스케일러 적용 중...\")\n",
    "    scaler = StandardScaler()\n",
    "    train_x = scaler.fit_transform(train_x)\n",
    "    dev_x   = scaler.transform(dev_x)\n",
    "    test_x  = scaler.transform(test_x)\n",
    "\n",
    "    param_grid = {\n",
    "        \"C\":     [0.1, 1, 10, 50],\n",
    "        \"gamma\": [\"scale\", 0.01, 0.001],\n",
    "        \"kernel\": [\"rbf\"],\n",
    "        \"class_weight\": [\"balanced\"]\n",
    "    }\n",
    "\n",
    "    svm = SVC()\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        svm,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(train_x, train_y)\n",
    "\n",
    "    best_svm = grid.best_estimator_\n",
    "\n",
    "    print(\"\\nBest Params:\", grid.best_params_)\n",
    "\n",
    "    print(\"\\n=== Dev 성능 ===\")\n",
    "    pred_dev = best_svm.predict(dev_x)\n",
    "    print(classification_report(dev_y, pred_dev))\n",
    "    print(confusion_matrix(dev_y, pred_dev))\n",
    "\n",
    "    print(\"\\n=== Test 성능 ===\")\n",
    "    pred_test = best_svm.predict(test_x)\n",
    "    print(classification_report(test_y, pred_test))\n",
    "    print(confusion_matrix(test_y, pred_test))\n",
    "\n",
    "    return best_svm, scaler, grid.best_params_\n",
    "\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 5. 실행 파트\n",
    "# ================================\n",
    "# 예시: 실제 사용 시 아래 변수만 데이터셋에 맞게 교체\n",
    "glove_path = \"glove.6B.300d.txt\"\n",
    "\n",
    "glove = load_glove(glove_path)\n",
    "lstm = NumpyLSTM(input_dim=300, hidden_dim=128)\n",
    "\n",
    "# 여러분의 분할된 텍스트/레이블 사용\n",
    "# train_texts, train_y\n",
    "# dev_texts, dev_y\n",
    "# test_texts, test_y\n",
    "\n",
    "train_vec = encode_dataset(train_texts, glove, lstm)\n",
    "dev_vec   = encode_dataset(dev_texts, glove, lstm)\n",
    "test_vec  = encode_dataset(test_texts, glove, lstm)\n",
    "\n",
    "svm_model, scaler, best_params = train_svm_rbf(\n",
    "    train_vec, train_y,\n",
    "    dev_vec, dev_y,\n",
    "    test_vec, test_y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fae76e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "성능 해석(중요)\n",
    "\n",
    "✔ TD는 dev/test 둘 다 0.85~0.93의 매우 좋은 성능\n",
    "✔ SLI는 test에서 1/6 = 17%, dev는 0%\n",
    "\n",
    "즉, 모델이 SLI를 거의 구별 못함 → 원인:\n",
    "\n",
    "1) 클래스 불균형 (SLI가 너무 적음)\n",
    "\n",
    "각각 train/dev/test에서 SLI가 6~7개 수준\n",
    "\n",
    "SVM + 작은 샘플 → 거의 불가능\n",
    "\n",
    "2) 문장 길이 짧거나 단서가 적으면 LSTM 인코더가 SLI를 못 잡음\n",
    "\n",
    "Word embedding 계열에서는 특히 문제됨.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88184a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 400000/400000 [00:17<00:00, 22589.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe loaded: 400000\n",
      "스케일러 적용 중...\n",
      "\n",
      "Best Params: {'C': 50, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "=== Dev 성능 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         SLI       0.25      0.14      0.18         7\n",
      "          TD       0.81      0.89      0.85        28\n",
      "\n",
      "    accuracy                           0.74        35\n",
      "   macro avg       0.53      0.52      0.51        35\n",
      "weighted avg       0.70      0.74      0.71        35\n",
      "\n",
      "[[ 1  6]\n",
      " [ 3 25]]\n",
      "\n",
      "=== Test 성능 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         SLI       0.50      0.67      0.57         6\n",
      "          TD       0.93      0.87      0.90        30\n",
      "\n",
      "    accuracy                           0.83        36\n",
      "   macro avg       0.71      0.77      0.73        36\n",
      "weighted avg       0.86      0.83      0.84        36\n",
      "\n",
      "[[ 4  2]\n",
      " [ 4 26]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 1. GloVe 불러오기\n",
    "# ================================\n",
    "def load_glove(path):\n",
    "    glove = {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, total=400000):\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vec = np.asarray(values[1:], dtype='float32')\n",
    "            glove[word] = vec\n",
    "    print(\"GloVe loaded:\", len(glove))\n",
    "    return glove\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 2. 간단한 NumPy LSTM 구현\n",
    "# ================================\n",
    "class NumpyLSTM:\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.W = np.random.randn(input_dim + hidden_dim, 4 * hidden_dim) * 0.1\n",
    "        self.b = np.zeros((4 * hidden_dim,))\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = np.zeros((self.hidden_dim,))\n",
    "        c = np.zeros((self.hidden_dim,))\n",
    "        for t in range(x.shape[0]):\n",
    "            xt = x[t]\n",
    "            concat = np.concatenate([h, xt])\n",
    "            gates = concat @ self.W + self.b\n",
    "\n",
    "            i = 1 / (1 + np.exp(-gates[:self.hidden_dim]))         # input gate\n",
    "            f = 1 / (1 + np.exp(-gates[self.hidden_dim:2*self.hidden_dim]))  # forget gate\n",
    "            o = 1 / (1 + np.exp(-gates[2*self.hidden_dim:3*self.hidden_dim])) # output gate\n",
    "            g = np.tanh(gates[3*self.hidden_dim:])                          # candidate\n",
    "\n",
    "            c = f * c + i * g\n",
    "            h = o * np.tanh(c)\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 3. 텍스트 → GloVe → LSTM 인코딩\n",
    "# ================================\n",
    "def encode_sentence(text, glove, lstm, max_len=50):\n",
    "    tokens = text.lower().split()\n",
    "    vecs = []\n",
    "\n",
    "    for tok in tokens[:max_len]:\n",
    "        if tok in glove:\n",
    "            vecs.append(glove[tok])\n",
    "        else:\n",
    "            vecs.append(np.zeros((300,)))\n",
    "\n",
    "    if len(vecs) == 0:\n",
    "        vecs.append(np.zeros((300,)))\n",
    "\n",
    "    return lstm.forward(np.array(vecs))\n",
    "\n",
    "\n",
    "def encode_dataset(texts, glove, lstm):\n",
    "    return np.array([encode_sentence(t, glove, lstm) for t in texts])\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 4. SVM(RBF 중심) + class_weight=balanced 탐색\n",
    "# ================================\n",
    "\n",
    "def train_svm_smote(train_x, train_y, dev_x, dev_y, test_x, test_y):\n",
    "\n",
    "    print(\"스케일러 적용 중...\")\n",
    "    scaler = StandardScaler()\n",
    "    train_x = scaler.fit_transform(train_x)\n",
    "    dev_x   = scaler.transform(dev_x)\n",
    "    test_x  = scaler.transform(test_x)\n",
    "\n",
    "    # 1️⃣ SMOTE 적용 (SLI 데이터 증가)\n",
    "    print(\"SMOTE 적용 중...\")\n",
    "    smote = SMOTE(k_neighbors=3, random_state=42)\n",
    "    train_x, train_y = smote.fit_resample(train_x, train_y)\n",
    "\n",
    "    print(\"SMOTE 후 클래스 분포:\", np.bincount(train_y))\n",
    "\n",
    "    # 2️⃣ 파라미터 그리드\n",
    "    param_grid = {\n",
    "        \"C\": [0.1, 1, 10, 50],\n",
    "        \"gamma\": [\"scale\", 0.01, 0.001],\n",
    "        \"kernel\": [\"rbf\"],\n",
    "        \"class_weight\": [\"balanced\"]\n",
    "    }\n",
    "\n",
    "    svm = SVC()\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        svm,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(train_x, train_y)\n",
    "\n",
    "    best_svm = grid.best_estimator_\n",
    "\n",
    "    print(\"\\nBest Params:\", grid.best_params_)\n",
    "\n",
    "    # 3️⃣ Dev 성능 확인\n",
    "    print(\"\\n=== Dev 성능 ===\")\n",
    "    pred_dev = best_svm.predict(dev_x)\n",
    "    print(classification_report(dev_y, pred_dev))\n",
    "    print(confusion_matrix(dev_y, pred_dev))\n",
    "\n",
    "    # 4️⃣ Test 성능 확인\n",
    "    print(\"\\n=== Test 성능 ===\")\n",
    "    pred_test = best_svm.predict(test_x)\n",
    "    print(classification_report(test_y, pred_test))\n",
    "    print(confusion_matrix(test_y, pred_test))\n",
    "\n",
    "    return best_svm, scaler, grid.best_params_\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 5. 실행 파트\n",
    "# ================================\n",
    "# 예시: 실제 사용 시 아래 변수만 데이터셋에 맞게 교체\n",
    "glove_path = \"glove.6B.300d.txt\"\n",
    "\n",
    "glove = load_glove(glove_path)\n",
    "lstm = NumpyLSTM(input_dim=300, hidden_dim=128)\n",
    "\n",
    "# 여러분의 분할된 텍스트/레이블 사용\n",
    "# train_texts, train_y\n",
    "# dev_texts, dev_y\n",
    "# test_texts, test_y\n",
    "\n",
    "train_vec = encode_dataset(train_texts, glove, lstm)\n",
    "dev_vec   = encode_dataset(dev_texts, glove, lstm)\n",
    "test_vec  = encode_dataset(test_texts, glove, lstm)\n",
    "\n",
    "svm_model, scaler, best_params = train_svm_rbf(\n",
    "    train_vec, train_y,\n",
    "    dev_vec, dev_y,\n",
    "    test_vec, test_y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eaa11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "✔ 결과가 Dev/Test에서 다르게 나온 건 데이터 분할 문제일 가능성이 매우 높음\n",
    "✔ Test 기준 SLI 성능은 꽤 괜찮아짐\n",
    "✔ 다음으로는 Stratified split이 가장 중요\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007ff7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7920a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading GloVe: 400000it [00:18, 22200.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe loaded: 400000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading GloVe: 400000it [00:18, 22156.00it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train_svm_rbf() takes 2 positional arguments but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w5/1h0crrlj5hx238pnm9g4gcgw0000gn/T/ipykernel_72955/2327561372.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0mtest_vec\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mencode_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m svm_model, scaler, best_params = train_svm_rbf(\n\u001b[0m\u001b[1;32m    210\u001b[0m     \u001b[0mtrain_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0mdev_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: train_svm_rbf() takes 2 positional arguments but 6 were given"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b4be7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
